{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is better to validate the images to see if face is detected or not (only one face should be detected) in every face angle before generating encodings. Afer validations, we can generate encoding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: There should be 'to_encode_faces' folder in the directory where this notebook (validateData_generateEncodings.ipynb) is located. All the images to encode should be inside 'to_encode_faces' folder in following format:**\n",
    "\n",
    "```\n",
    "to_encode/\n",
    "├── <person_1_id>-<university>-<first_name>-<last_name>/\n",
    "│   ├── front.jpg\n",
    "│   ├── down.jpg\n",
    "│   ├── up.jpg\n",
    "│   ├── left.jpg\n",
    "│   └── right.jpg\n",
    "├── <person_2_id>-<university>-<first_name>-<last_name>/\n",
    "│   ├── front.jpg\n",
    "│   ├── down.jpg\n",
    "│   ├── up.jpg\n",
    "│   ├── left.jpg\n",
    "│   └── right.jpg\n",
    "├── <person_3_id>-<university>-<first_name>-<last_name>/\n",
    "│   ├── front.jpg\n",
    "│   ├── down.jpg\n",
    "│   ├── up.jpg\n",
    "│   ├── left.jpg\n",
    "│   └── right.jpg\n",
    "└── ...\n",
    "\n",
    "Don't keep < or > in the folder name! It is used to denote a variable which can have different values. \n",
    "The folder should be named like: 23140736-BCU-ABHASH-RAI\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"./to_encode_faces/23140736-BCU-ABHASH-RAI/down.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140736-BCU-ABHASH-RAI/front.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140736-BCU-ABHASH-RAI/left.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140736-BCU-ABHASH-RAI/right.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140736-BCU-ABHASH-RAI/up.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/down.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/front.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/left.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/right.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/up.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/down.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/front.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/left.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/right.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/up.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/down.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/front.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/left.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/right.jpg\" - Single face detected. Good.\n",
      "\"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/up.jpg\" - Single face detected. Good.\n",
      "Can detect a single face in every image. All good. Proceed to generating encodings.\n"
     ]
    }
   ],
   "source": [
    "def validate_images(images_to_encode_folder_path):\n",
    "\n",
    "    to_recapture = []\n",
    "\n",
    "    all_directories = os.listdir(images_to_encode_folder_path)\n",
    "\n",
    "    for folder in all_directories:\n",
    "\n",
    "        all_files = os.listdir(f'{images_to_encode_folder_path}/{folder}')\n",
    "        img_path = [filename for filename in all_files if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp'))] # Filter for image files (e.g., .jpg, .png, .jpeg)\n",
    "        \n",
    "        for img in img_path:\n",
    "            \n",
    "            image = cv2.imread(f'{images_to_encode_folder_path}/{folder}/{img}')\n",
    "            \n",
    "            # Detect faces in the image\n",
    "            face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "            current_img_path = f'{images_to_encode_folder_path}/{folder}/{img}'\n",
    "            \n",
    "            if len(face_locations) == 0:\n",
    "                print(f'* \"{current_img_path}\" - No Faces Detected! Bad!')\n",
    "                to_recapture.append(current_img_path)\n",
    "            elif len(face_locations) > 1:\n",
    "                print(f'* \"{current_img_path}\" - More than one Faces Detected! Bad!')\n",
    "                to_recapture.append(current_img_path)\n",
    "            elif len(face_locations) == 1:\n",
    "                print(f'\"{current_img_path}\" - Single face detected. Good.')\n",
    "\n",
    "    if len(to_recapture) != 0:           \n",
    "        print(f'\\n\\nThe below images either have multiple faces or cannot detect a face at all. Recapture the image of people given below to have detectable single face:')\n",
    "        print(to_recapture)\n",
    "    else:\n",
    "        print('\\n\\nCan detect a single face in every image. All good. Proceed to generating encodings.')\n",
    "\n",
    "validate_images(\"./to_encode_faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Face Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated face encodings of \"./photos/23140736-BCU-ABHASH-RAI/down.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140736-BCU-ABHASH-RAI/front.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140736-BCU-ABHASH-RAI/left.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140736-BCU-ABHASH-RAI/right.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140736-BCU-ABHASH-RAI/up.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140741-BCU-NANAK-SHRESTHA/down.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140741-BCU-NANAK-SHRESTHA/front.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140741-BCU-NANAK-SHRESTHA/left.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140741-BCU-NANAK-SHRESTHA/right.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140741-BCU-NANAK-SHRESTHA/up.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140745-BCU-SADIKSHYA-GHIMIRE/down.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140745-BCU-SADIKSHYA-GHIMIRE/front.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140745-BCU-SADIKSHYA-GHIMIRE/left.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140745-BCU-SADIKSHYA-GHIMIRE/right.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140745-BCU-SADIKSHYA-GHIMIRE/up.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140750-BCU-SUDEEP-FULLEL/down.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140750-BCU-SUDEEP-FULLEL/front.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140750-BCU-SUDEEP-FULLEL/left.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140750-BCU-SUDEEP-FULLEL/right.jpg\"\n",
      "Successfully generated face encodings of \"./photos/23140750-BCU-SUDEEP-FULLEL/up.jpg\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_encodings(images_to_encode_folder_path, path_to_store_encodings):\n",
    "\n",
    "    all_face_encodings = {}\n",
    "\n",
    "    all_directories = os.listdir(images_to_encode_folder_path)\n",
    "\n",
    "    for folder in all_directories:\n",
    "        \n",
    "        face_encodings = []\n",
    "\n",
    "        all_files = os.listdir(f'{images_to_encode_folder_path}/{folder}')\n",
    "        img_path = [filename for filename in all_files if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp'))] # Filter for image files (e.g., .jpg, .png, .jpeg)\n",
    "        \n",
    "        for img in img_path:\n",
    "            image = face_recognition.api.load_image_file(f'{images_to_encode_folder_path}/{folder}/{img}')\n",
    "            encoding = face_recognition.api.face_encodings(image, model='large')\n",
    "            if len(encoding) == 1:\n",
    "                face_encodings.append(encoding[0])\n",
    "                print(f'Successfully generated face encodings of \"{images_to_encode_folder_path}/{folder}/{img}\"')\n",
    "            elif len(encoding) == 0:\n",
    "                print(f'No face detected in {images_to_encode_folder_path}/{folder}/{img}')\n",
    "                return\n",
    "            elif len(encoding) > 1:\n",
    "                print(f'More than one faces detected in {images_to_encode_folder_path}/{folder}/{img}')\n",
    "                return\n",
    "            \n",
    "        all_face_encodings[folder] = face_encodings\n",
    "        \n",
    "    with open(path_to_store_encodings, 'wb') as file:\n",
    "        pickle.dump(all_face_encodings, file)\n",
    "\n",
    "generate_encodings(\n",
    "    images_to_encode_folder_path = \"./to_encode_faces\",\n",
    "    path_to_store_encodings = './encodings/multiple_angles_faces_encodings'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated face encodings of \"./to_encode_faces/23140736-BCU-ABHASH-RAI/down.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140736-BCU-ABHASH-RAI/front.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140736-BCU-ABHASH-RAI/left.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140736-BCU-ABHASH-RAI/right.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140736-BCU-ABHASH-RAI/up.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/down.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/front.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/left.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/right.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140741-BCU-NANAK-SHRESTHA/up.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/down.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/front.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/left.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/right.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140745-BCU-SADIKSHYA-GHIMIRE/up.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/down.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/front.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/left.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/right.jpg\"\n",
      "Successfully generated face encodings of \"./to_encode_faces/23140750-BCU-SUDEEP-FULLEL/up.jpg\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_encodings(images_to_encode_folder_path, path_to_store_encodings):\n",
    "\n",
    "    all_face_encodings = {}\n",
    "\n",
    "    all_directories = os.listdir(images_to_encode_folder_path)\n",
    "\n",
    "    for folder in all_directories:\n",
    "        \n",
    "        face_encodings = []\n",
    "\n",
    "        all_files = os.listdir(f'{images_to_encode_folder_path}/{folder}')\n",
    "        img_path = [filename for filename in all_files if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.gif', '.bmp'))] # Filter for image files (e.g., .jpg, .png, .jpeg)\n",
    "        \n",
    "        for img in img_path:\n",
    "            image = face_recognition.api.load_image_file(f'{images_to_encode_folder_path}/{folder}/{img}')\n",
    "            encoding = face_recognition.api.face_encodings(image, model='large')\n",
    "            if len(encoding) == 1:\n",
    "                face_encodings.append(encoding[0])\n",
    "                print(f'Successfully generated face encodings of \"{images_to_encode_folder_path}/{folder}/{img}\"')\n",
    "            elif len(encoding) == 0:\n",
    "                print(f'No face detected in {images_to_encode_folder_path}/{folder}/{img}')\n",
    "                return\n",
    "            elif len(encoding) > 1:\n",
    "                print(f'More than one faces detected in {images_to_encode_folder_path}/{folder}/{img}')\n",
    "                return\n",
    "            \n",
    "        all_face_encodings[folder] = face_encodings\n",
    "        \n",
    "    with open(path_to_store_encodings, 'wb') as file:\n",
    "        pickle.dump(all_face_encodings, file)\n",
    "\n",
    "generate_encodings(\n",
    "    images_to_encode_folder_path = \"./to_encode_faces\",\n",
    "    path_to_store_encodings = './encodings/multiple_angles_faces_encodings'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
